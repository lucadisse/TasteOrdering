{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTBPOkzBm51c"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcIwvG5aZ4vO"
   },
   "outputs": [],
   "source": [
    "num_triplets = len(pd.read_csv(\"/content/drive/My Drive/train_triplets.txt\").index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zgCRsxI9Mv6B",
    "outputId": "4cfc2dd4-c1f9-4efd-ba7f-3559fb823ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  10010\n"
     ]
    }
   ],
   "source": [
    "path = '/content/drive/My Drive/food/'\n",
    "data_dir = pathlib.Path(path)\n",
    "image_count = len(list(data_dir.glob('*.jpg')))\n",
    "print('Number of training images: ', image_count)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 420 #second index of shape 470 original\n",
    "IMG_WIDTH = 300 #first index of shape\n",
    "EPOCHS = 8\n",
    "STEPS_PER_EPOCH = np.ceil(num_triplets/BATCH_SIZE)\n",
    "margin = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "id": "4akuicdrsbpi",
    "outputId": "674e9e1c-6ac6-4d02-e045-e148866c8056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(300, 420, 3), dtype=float32, numpy=\n",
       "array([[[0.12052289, 0.10483661, 0.21071897],\n",
       "        [0.11137256, 0.09490196, 0.20313728],\n",
       "        [0.10196079, 0.08235295, 0.20000002],\n",
       "        ...,\n",
       "        [0.8444448 , 0.7934644 , 0.83137286],\n",
       "        [0.80705935, 0.7560789 , 0.8172551 ],\n",
       "        [0.7890198 , 0.7380394 , 0.8083662 ]],\n",
       "\n",
       "       [[0.0460915 , 0.0265817 , 0.14393464],\n",
       "        [0.11596079, 0.09643138, 0.21384315],\n",
       "        [0.10068628, 0.08107844, 0.1987255 ],\n",
       "        ...,\n",
       "        [0.7475816 , 0.6966012 , 0.7319606 ],\n",
       "        [0.76270574, 0.7147841 , 0.76678395],\n",
       "        [0.77958804, 0.72886264, 0.79485595]],\n",
       "\n",
       "       [[0.0990523 , 0.07944445, 0.20460786],\n",
       "        [0.13787583, 0.11826798, 0.24343139],\n",
       "        [0.09313726, 0.07352941, 0.19869283],\n",
       "        ...,\n",
       "        [0.8014704 , 0.75049   , 0.78327864],\n",
       "        [0.8247057 , 0.77686256, 0.82186234],\n",
       "        [0.82920486, 0.7819935 , 0.83685184]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78406376, 0.74144936, 0.7176585 ],\n",
       "        [0.8177783 , 0.78640574, 0.7573861 ],\n",
       "        [0.82717943, 0.8167219 , 0.7826261 ],\n",
       "        ...,\n",
       "        [0.0397602 , 0.04226563, 0.05010878],\n",
       "        [0.0062086 , 0.00709097, 0.01493411],\n",
       "        [0.01285342, 0.02750462, 0.03168768]],\n",
       "\n",
       "       [[0.7376075 , 0.69480366, 0.6708167 ],\n",
       "        [0.77717614, 0.7457252 , 0.71654874],\n",
       "        [0.7614705 , 0.751013  , 0.7144116 ],\n",
       "        ...,\n",
       "        [0.11127511, 0.11127511, 0.11911824],\n",
       "        [0.07639265, 0.07960828, 0.08721618],\n",
       "        [0.05528144, 0.07000681, 0.07398731]],\n",
       "\n",
       "       [[0.79215693, 0.7419608 , 0.7103268 ],\n",
       "        [0.8352942 , 0.8007844 , 0.76549023],\n",
       "        [0.78823537, 0.77777785, 0.7411765 ],\n",
       "        ...,\n",
       "        [0.06666655, 0.06666655, 0.07450969],\n",
       "        [0.05803941, 0.06431382, 0.06274534],\n",
       "        [0.02928144, 0.03712457, 0.03320301]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.io.read_file('/content/drive/My Drive/food/00029.jpg')\n",
    "img = tf.image.decode_jpeg(img, channels=3)\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XDfFI88gwWb"
   },
   "outputs": [],
   "source": [
    "def image_vector(names):\n",
    "  parts = tf.strings.split(names, \" \")\n",
    "  file_dir = '/content/drive/My Drive/food/'    \n",
    "  image_names = parts\n",
    "  img1 = tf.io.read_file(file_dir+parts[0]+'.jpg')\n",
    "  img1 = tf.image.decode_jpeg(img1, channels=3)\n",
    "  img1 = tf.image.convert_image_dtype(img1, tf.float32)\n",
    "  img1 = tf.image.resize(img1, [IMG_WIDTH, IMG_HEIGHT])\n",
    "  img2 = tf.io.read_file(file_dir+parts[1]+'.jpg')\n",
    "  img2 = tf.image.decode_jpeg(img2, channels=3)\n",
    "  img2 = tf.image.convert_image_dtype(img2, tf.float32)\n",
    "  img2 = tf.image.resize(img2, [IMG_WIDTH, IMG_HEIGHT])\n",
    "  img3 = tf.io.read_file(file_dir+parts[2]+'.jpg')\n",
    "  img3 = tf.image.decode_jpeg(img3, channels=3)\n",
    "  img3 = tf.image.convert_image_dtype(img3, tf.float32)\n",
    "  img3 = tf.image.resize(img3, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "  #change order of the images\n",
    "  image_triplets = (img1, img2, img3)\n",
    "\n",
    "\n",
    "  return image_triplets, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OvwKrifdiAfw",
    "outputId": "58595651-0c12-48ef-984f-db74faa54c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TextLineDatasetV2 shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "triplet_names = tf.data.TextLineDataset(\"/content/drive/My Drive/train_triplets.txt\")\n",
    "print(triplet_names)\n",
    "triplet_ds = triplet_names.map(image_vector, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#triplet_test  = triplet_ds.take(3000)\n",
    "\n",
    "#triplet_train = triplet_ds.skip(3000)\n",
    "triplet_train = triplet_ds\n",
    "triplet_train = triplet_train.batch(BATCH_SIZE).repeat(EPOCHS)\n",
    "triplet_train = triplet_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ti7IM1om51w"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PObdC8EvbMGT"
   },
   "outputs": [],
   "source": [
    "def triplet_distances(anch, pos, neg):\n",
    "  d_pos = tf.reduce_sum(tf.square(anch - pos), 1)\n",
    "  d_neg = tf.reduce_sum(tf.square(anch - neg), 1)\n",
    "\n",
    "  #wenn die Reihenfolge korrekt ist, dann ist der dpos kleiner und der loss null\n",
    "  loss = tf.maximum(0., margin + d_pos - d_neg)\n",
    "  return tf.reduce_mean(loss)\n",
    "\n",
    "def model_loss(label, distance):\n",
    "  return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5un1YWuWKZu"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def score(losses):\n",
    "  m = tf.constant(margin)\n",
    "  losses = losses - m\n",
    "  #wenn A nÃ¤her B dann label 1\n",
    "  label = tf.constant(1.) - tf.math.ceil(K.clip(losses, 0, 1))\n",
    "  return label\n",
    "\n",
    "#def metric(y_true, score): \n",
    "#    true_positives = tf.math.count_nonzero(score)\n",
    "#    all_counts = tf.size(score)\n",
    "#    return true_positives / all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCTjd5C0AzhQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4\", trainable=False),\n",
    "    #tf.keras.layers.Dropout(0.3),\n",
    "    #tf.keras.layers.Dense(900, activation='relu'),\n",
    "    tf.keras.layers.Dense(4500, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(150, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "    ])\n",
    "\n",
    "#model.build([None, IMG_WIDTH, IMG_HEIGHT, 3])  # Batch input shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaK8Elttm512"
   },
   "source": [
    "## Transfer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShLmdBBym512",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputA = tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3), name='A')\n",
    "inputB = tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3), name='B')\n",
    "inputC = tf.keras.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3), name='C')\n",
    "\n",
    "A_features = model(inputA)\n",
    "B_features = model(inputB)\n",
    "C_features = model(inputC)\n",
    "\n",
    "#outputs of model is actually the loss, if > 0 we have C belongs to A\n",
    "trip_loss1 = triplet_distances(A_features, B_features, C_features)\n",
    "#trip_loss2 = triplet_distances(A_features, C_features, B_features)\n",
    "\n",
    "label = score(trip_loss1)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputA, inputB, inputC], \n",
    "                       outputs=[trip_loss1,label])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkWOO1TUm515"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=model_loss,\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss_weights=[1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "zHzHFK5vwgqG",
    "outputId": "3400ab36-596b-4681-cb0c-28fd1d00bfa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1860/1860 [==============================] - 925s 498ms/step - loss: 0.2000 - tf_op_layer_Mean_1_loss: 0.2000 - tf_op_layer_Sub_9_loss: 0.9876\n",
      "Epoch 2/8\n",
      "1860/1860 [==============================] - 925s 497ms/step - loss: 0.1796 - tf_op_layer_Mean_1_loss: 0.1796 - tf_op_layer_Sub_9_loss: 0.9968\n",
      "Epoch 3/8\n",
      "1860/1860 [==============================] - 924s 497ms/step - loss: 0.1661 - tf_op_layer_Mean_1_loss: 0.1661 - tf_op_layer_Sub_9_loss: 0.9973\n",
      "Epoch 4/8\n",
      "1860/1860 [==============================] - 924s 497ms/step - loss: 0.1527 - tf_op_layer_Mean_1_loss: 0.1527 - tf_op_layer_Sub_9_loss: 0.9995\n",
      "Epoch 5/8\n",
      "1860/1860 [==============================] - 924s 497ms/step - loss: 0.1394 - tf_op_layer_Mean_1_loss: 0.1394 - tf_op_layer_Sub_9_loss: 1.0000\n",
      "Epoch 6/8\n",
      "1860/1860 [==============================] - 923s 496ms/step - loss: 0.1264 - tf_op_layer_Mean_1_loss: 0.1264 - tf_op_layer_Sub_9_loss: 1.0000\n",
      "Epoch 7/8\n",
      "1860/1860 [==============================] - 924s 497ms/step - loss: 0.1142 - tf_op_layer_Mean_1_loss: 0.1142 - tf_op_layer_Sub_9_loss: 1.0000\n",
      "Epoch 8/8\n",
      "1860/1860 [==============================] - 925s 498ms/step - loss: 0.1018 - tf_op_layer_Mean_1_loss: 0.1018 - tf_op_layer_Sub_9_loss: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe9c00dd748>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(triplet_train, epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "mxFd8Sl1n2kR",
    "outputId": "de07228f-bec4-4a00-8c73-9708a8646ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/saved_model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/content/drive/My Drive/saved_model/my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xN0AtDNnm52F"
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35fZj-6im52F"
   },
   "outputs": [],
   "source": [
    "# store submission in csv triplet_test\n",
    "test_names = tf.data.TextLineDataset(\"/content/drive/My Drive/test_triplets.txt\")\n",
    "test_ds = test_names.map(image_vector, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.batch(1)\n",
    "y_sub = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "DbAar801pykN",
    "outputId": "75c45f98-4987-48d9-96f9-c0f4a7cb78cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "59539    1\n",
       "59540    0\n",
       "59541    1\n",
       "59542    0\n",
       "59543    1\n",
       "Length: 59544, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.Series(y_sub[1])\n",
    "submission = submission.astype(int)\n",
    "submission.to_csv('/content/drive/My Drive/prediction.csv', index=False, header=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
